{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RZOuS9LWQvv"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  !pip install tf-nightly\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "!pip install tensorflow-datasets\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMHwYXHXCar3"
      },
      "outputs": [],
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
        "\n",
        "train_file_path = \"train-data.tsv\"\n",
        "test_file_path = \"valid-data.tsv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_h508FEClxO"
      },
      "outputs": [],
      "source": [
        "# Read the data\n",
        "train_data = pd.read_csv(train_file_path, sep='\\t', header=None, names=['label', 'message'])\n",
        "test_data = pd.read_csv(test_file_path, sep='\\t', header=None, names=['label', 'message'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOMKywn4zReN"
      },
      "outputs": [],
      "source": [
        "# Explore the data\n",
        "print(f\"Training data shape: {train_data.shape}\")\n",
        "print(f\"Testing data shape: {test_data.shape}\")\n",
        "print(\"\\nSample of training data:\")\n",
        "print(train_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of ham and spam messages\n",
        "ham_count = len(train_data[train_data['label'] == 'ham'])\n",
        "spam_count = len(train_data[train_data['label'] == 'spam'])\n",
        "print(f\"\\nHam messages: {ham_count}\")\n",
        "print(f\"Spam messages: {spam_count}\")\n",
        "print(f\"Percentage of spam messages: {spam_count / (ham_count + spam_count) * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "SCc_A46gY07V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data\n",
        "# Convert labels to numeric values\n",
        "train_labels = np.array([0 if label == 'ham' else 1 for label in train_data['label']])\n",
        "test_labels = np.array([0 if label == 'ham' else 1 for label in test_data['label']])"
      ],
      "metadata": {
        "id": "TkKaeHdSY3Eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and pad the text\n",
        "vocab_size = 10000  # Maximum number of words to tokenize\n",
        "max_length = 100    # Maximum length of sequences\n",
        "trunc_type = 'post' # Truncation type\n",
        "padding_type = 'post' # Padding type\n",
        "oov_tok = '<OOV>'   # Out of vocabulary token\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(train_data['message'])"
      ],
      "metadata": {
        "id": "wtRRBQNNY5Z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get word index\n",
        "word_index = tokenizer.word_index\n",
        "print(f\"\\nNumber of unique words: {len(word_index)}\")"
      ],
      "metadata": {
        "id": "i63KitnDY8ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text to sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_data['message'])\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data['message'])"
      ],
      "metadata": {
        "id": "TmukQSkIY-xF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ],
      "metadata": {
        "id": "5UNhcOdGZAuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shapes\n",
        "print(f\"\\nTraining sequences shape: {train_padded.shape}\")\n",
        "print(f\"Testing sequences shape: {test_padded.shape}\")"
      ],
      "metadata": {
        "id": "CQDUkxw7ZCz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "embedding_dim = 16\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "_og39CvDZFP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "epochs = 30\n",
        "history = model.fit(\n",
        "    train_padded, train_labels,\n",
        "    epochs=epochs,\n",
        "    validation_data=(test_padded, test_labels),\n",
        "    verbose=1,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZBR94QgxZJMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "beeB4oEoZLa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "loss, accuracy = model.evaluate(test_padded, test_labels)\n",
        "print(f\"\\nTest Accuracy: {accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "id": "3qV_XHkCZN1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict if a message is spam or ham\n",
        "def predict_message(message):\n",
        "    \"\"\"\n",
        "    Predicts if a message is spam or ham.\n",
        "\n",
        "    Args:\n",
        "        message (str): The SMS message to classify\n",
        "\n",
        "    Returns:\n",
        "        list: [probability_of_spam, \"spam\" or \"ham\"]\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "810WERJzZQUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the message\n",
        "    sequence = tokenizer.texts_to_sequences([message])\n",
        "    padded = pad_sequences(sequence, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ],
      "metadata": {
        "id": "4F69IkKgZTDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction\n",
        "    prediction = model.predict(padded)[0][0]"
      ],
      "metadata": {
        "id": "8_CBRPC4ZV7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Return the result\n",
        "    return [float(prediction), \"spam\" if prediction > 0.5 else \"ham\"]"
      ],
      "metadata": {
        "id": "id2M8O48ZYUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the function with some examples\n",
        "test_messages = [\n",
        "    \"Hey, how are you doing?\",\n",
        "    \"Congratulations! You've won a $1000 gift card. Call 555-123-4567 to claim now!\",\n",
        "    \"Don't forget about our meeting tomorrow.\",\n",
        "    \"URGENT: Your account has been compromised. Reply with your details to secure.\"\n",
        "]\n",
        "\n",
        "for message in test_messages:\n",
        "    prediction = predict_message(message)\n",
        "    print(f\"Message: '{message}'\")\n",
        "    print(f\"Prediction: {prediction[1]} (probability: {prediction[0]:.4f})\")\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "UiENocl4ZaQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "q21fIHg2ZehI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions for test data\n",
        "y_pred = model.predict(test_padded)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int).flatten()"
      ],
      "metadata": {
        "id": "-I0tcBhKZhEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create confusion matrix\n",
        "cm = confusion_matrix(test_labels, y_pred_classes)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['ham', 'spam'])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fLNGa0lOZi8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final visualization: Display some misclassified examples\n",
        "misclassified_indices = np.where(y_pred_classes != test_labels)[0]\n",
        "\n",
        "if len(misclassified_indices) > 0:\n",
        "    print(\"\\nSome misclassified examples:\")\n",
        "    for i in np.random.choice(misclassified_indices, min(5, len(misclassified_indices)), replace=False):\n",
        "        message = test_data['message'].iloc[i]\n",
        "        true_label = 'ham' if test_labels[i] == 0 else 'spam'\n",
        "        pred_label = 'ham' if y_pred_classes[i] == 0 else 'spam'\n",
        "        confidence = y_pred[i][0] if pred_label == 'spam' else 1 - y_pred[i][0]\n",
        "\n",
        "        print(f\"Message: '{message[:100]}...' if len(message) > 100 else message\")\n",
        "        print(f\"True label: {true_label}\")\n",
        "        print(f\"Predicted label: {pred_label} (confidence: {confidence:.4f})\")\n",
        "        print()\n",
        "else:\n",
        "    print(\"\\nNo misclassified examples in the test set!\")"
      ],
      "metadata": {
        "id": "SfmYJNsVZk5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9tD9yACG6M9"
      },
      "outputs": [],
      "source": [
        "# function to predict messages based on model\n",
        "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
        "def predict_message(pred_text):\n",
        "\n",
        "\n",
        "\n",
        "  return (prediction)\n",
        "\n",
        "pred_text = \"how are you doing today?\"\n",
        "\n",
        "prediction = predict_message(pred_text)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxotov85SjsC"
      },
      "outputs": [],
      "source": [
        "# Run this cell to test your function and model. Do not modify contents.\n",
        "def test_predictions():\n",
        "  test_messages = [\"how are you doing today\",\n",
        "                   \"sale today! to stop texts call 98912460324\",\n",
        "                   \"i dont want to go. can we try it a different day? available sat\",\n",
        "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
        "                   \"you have won £1000 cash! call to claim your prize.\",\n",
        "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
        "                   \"wow, is your arm alright. that happened to me one time too\"\n",
        "                  ]\n",
        "\n",
        "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
        "  passed = True\n",
        "\n",
        "  for msg, ans in zip(test_messages, test_answers):\n",
        "    prediction = predict_message(msg)\n",
        "    if prediction[1] != ans:\n",
        "      passed = False\n",
        "\n",
        "  if passed:\n",
        "    print(\"You passed the challenge. Great job!\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying.\")\n",
        "\n",
        "test_predictions()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "fcc_sms_text_classification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {}
  },
  "nbformat": 4,
  "nbformat_minor": 0
}